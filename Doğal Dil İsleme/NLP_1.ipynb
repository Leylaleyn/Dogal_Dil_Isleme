{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43bab143",
   "metadata": {},
   "source": [
    "#### Tokenization: Bütün bir yazıyı oluşturan her bir sözcüğü ayırma işlemidir. Normalization: Datayı temizleme işlemidir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332f2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aleyna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fd8ec",
   "metadata": {},
   "source": [
    "#### word_tokenize modülü bana her iki cümledeki her bir kelimeyi birbirinden ayıracakken, sent_tokenize modülünü sadece iki cümleyi birbirinden ayırmak için kullanırız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87536b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ee7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Alan Mathison Turing , İngiliz matematikçi, bilgisayar bilimcisi ve kriptolog. Bilgisayar biliminin kurucusu sayılır. Geliştirmiş olduğu Turing testi ile makinelerin ve bilgisayarların düşünme yetisine sahip olup olamayacakları konusunda bir kriter öne sürmüştür.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e714e11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan',\n",
       " 'Mathison',\n",
       " 'Turing',\n",
       " ',',\n",
       " 'İngiliz',\n",
       " 'matematikçi,',\n",
       " 'bilgisayar',\n",
       " 'bilimcisi',\n",
       " 've',\n",
       " 'kriptolog.',\n",
       " 'Bilgisayar',\n",
       " 'biliminin',\n",
       " 'kurucusu',\n",
       " 'sayılır.',\n",
       " 'Geliştirmiş',\n",
       " 'olduğu',\n",
       " 'Turing',\n",
       " 'testi',\n",
       " 'ile',\n",
       " 'makinelerin',\n",
       " 've',\n",
       " 'bilgisayarların',\n",
       " 'düşünme',\n",
       " 'yetisine',\n",
       " 'sahip',\n",
       " 'olup',\n",
       " 'olamayacakları',\n",
       " 'konusunda',\n",
       " 'bir',\n",
       " 'kriter',\n",
       " 'öne',\n",
       " 'sürmüştür.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()  # görüldüğü üzere tokenleştirme işlemi yapmış olduk fakat çok sağlıklı değil çünkü \",\" \".\" gibi şeyleri de kelimelere dahil etmiştir matematikçi.  matematikçi, olan kelimeleri makine farklı algılayacaktır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1176fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan',\n",
       " 'Mathison',\n",
       " 'Turing',\n",
       " ',',\n",
       " 'İngiliz',\n",
       " 'matematikçi',\n",
       " ',',\n",
       " 'bilgisayar',\n",
       " 'bilimcisi',\n",
       " 've',\n",
       " 'kriptolog',\n",
       " '.',\n",
       " 'Bilgisayar',\n",
       " 'biliminin',\n",
       " 'kurucusu',\n",
       " 'sayılır',\n",
       " '.',\n",
       " 'Geliştirmiş',\n",
       " 'olduğu',\n",
       " 'Turing',\n",
       " 'testi',\n",
       " 'ile',\n",
       " 'makinelerin',\n",
       " 've',\n",
       " 'bilgisayarların',\n",
       " 'düşünme',\n",
       " 'yetisine',\n",
       " 'sahip',\n",
       " 'olup',\n",
       " 'olamayacakları',\n",
       " 'konusunda',\n",
       " 'bir',\n",
       " 'kriter',\n",
       " 'öne',\n",
       " 'sürmüştür',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de3e008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan Mathison Turing , İngiliz matematikçi, bilgisayar bilimcisi ve kriptolog.',\n",
       " 'Bilgisayar biliminin kurucusu sayılır.',\n",
       " 'Geliştirmiş olduğu Turing testi ile makinelerin ve bilgisayarların düşünme yetisine sahip olup olamayacakları konusunda bir kriter öne sürmüştür.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7e1695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan\n",
      "Mathison\n",
      "Turing\n",
      ",\n",
      "İngiliz\n",
      "matematikçi\n",
      ",\n",
      "bilgisayar\n",
      "bilimcisi\n",
      "ve\n",
      "kriptolog\n",
      ".\n",
      "Bilgisayar\n",
      "biliminin\n",
      "kurucusu\n",
      "sayılır\n",
      ".\n",
      "Geliştirmiş\n",
      "olduğu\n",
      "Turing\n",
      "testi\n",
      "ile\n",
      "makinelerin\n",
      "ve\n",
      "bilgisayarların\n",
      "düşünme\n",
      "yetisine\n",
      "sahip\n",
      "olup\n",
      "olamayacakları\n",
      "konusunda\n",
      "bir\n",
      "kriter\n",
      "öne\n",
      "sürmüştür\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in word_tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d3b98c-4be9-4412-a46d-d8b694628380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan Mathison Turing , İngiliz matematikçi, bilgisayar bilimcisi ve kriptolog.\n",
      "\n",
      "\n",
      "Bilgisayar biliminin kurucusu sayılır.\n",
      "\n",
      "\n",
      "Geliştirmiş olduğu Turing testi ile makinelerin ve bilgisayarların düşünme yetisine sahip olup olamayacakları konusunda bir kriter öne sürmüştür.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sent_tokenize(text):\n",
    "    print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432aa184",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33daf96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aleyna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23652d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words ler genellikle gereksiz kelimelerdir cümle akışını güzelleştirmek için kullanılan fakat veri analizi yaparken pek de anlam ifade etmeyen kelimelerdir bunlar ingilizce de a,the, and gibi kelimelerdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f436c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2d402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Fazıl Say was born in 1970. His father, Ahmet Say was an author and musicologist. His mother, Gürgün Say was a pharmacist. His grandfather Fazıl Say with whom he shares the same name with was a member of the Spartakusbund.Say was a child prodigy, who was able to do basic arithmetic with 4-digit numbers at the age of two.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78e6a0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')  # ingilizcede ki stopwords'ler nedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beff6c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acaba',\n",
       " 'ama',\n",
       " 'aslında',\n",
       " 'az',\n",
       " 'bazı',\n",
       " 'belki',\n",
       " 'biri',\n",
       " 'birkaç',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bu',\n",
       " 'çok',\n",
       " 'çünkü',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'de',\n",
       " 'defa',\n",
       " 'diye',\n",
       " 'eğer',\n",
       " 'en',\n",
       " 'gibi',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hepsi',\n",
       " 'her',\n",
       " 'hiç',\n",
       " 'için',\n",
       " 'ile',\n",
       " 'ise',\n",
       " 'kez',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'mı',\n",
       " 'mu',\n",
       " 'mü',\n",
       " 'nasıl',\n",
       " 'ne',\n",
       " 'neden',\n",
       " 'nerde',\n",
       " 'nerede',\n",
       " 'nereye',\n",
       " 'niçin',\n",
       " 'niye',\n",
       " 'o',\n",
       " 'sanki',\n",
       " 'şey',\n",
       " 'siz',\n",
       " 'şu',\n",
       " 'tüm',\n",
       " 've',\n",
       " 'veya',\n",
       " 'ya',\n",
       " 'yani']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('turkish') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57142f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gereksiz = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd37977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33baf6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fazıl',\n",
       " 'Say',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " '1970',\n",
       " '.',\n",
       " 'His',\n",
       " 'father',\n",
       " ',',\n",
       " 'Ahmet',\n",
       " 'Say',\n",
       " 'was',\n",
       " 'an',\n",
       " 'author',\n",
       " 'and',\n",
       " 'musicologist',\n",
       " '.',\n",
       " 'His',\n",
       " 'mother',\n",
       " ',',\n",
       " 'Gürgün',\n",
       " 'Say',\n",
       " 'was',\n",
       " 'a',\n",
       " 'pharmacist',\n",
       " '.',\n",
       " 'His',\n",
       " 'grandfather',\n",
       " 'Fazıl',\n",
       " 'Say',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'he',\n",
       " 'shares',\n",
       " 'the',\n",
       " 'same',\n",
       " 'name',\n",
       " 'with',\n",
       " 'was',\n",
       " 'a',\n",
       " 'member',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Spartakusbund.Say',\n",
       " 'was',\n",
       " 'a',\n",
       " 'child',\n",
       " 'prodigy',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'able',\n",
       " 'to',\n",
       " 'do',\n",
       " 'basic',\n",
       " 'arithmetic',\n",
       " 'with',\n",
       " '4-digit',\n",
       " 'numbers',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " 'two',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65916993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenleştirdiğimiz kelimerden stopwords olanları çıkaracağız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e31ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "for kelime in words:\n",
    "    if kelime not in gereksiz:\n",
    "        filtered_words.append(kelime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b77b768f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fazıl',\n",
       " 'Say',\n",
       " 'born',\n",
       " '1970',\n",
       " '.',\n",
       " 'His',\n",
       " 'father',\n",
       " ',',\n",
       " 'Ahmet',\n",
       " 'Say',\n",
       " 'author',\n",
       " 'musicologist',\n",
       " '.',\n",
       " 'His',\n",
       " 'mother',\n",
       " ',',\n",
       " 'Gürgün',\n",
       " 'Say',\n",
       " 'pharmacist',\n",
       " '.',\n",
       " 'His',\n",
       " 'grandfather',\n",
       " 'Fazıl',\n",
       " 'Say',\n",
       " 'shares',\n",
       " 'name',\n",
       " 'member',\n",
       " 'Spartakusbund.Say',\n",
       " 'child',\n",
       " 'prodigy',\n",
       " ',',\n",
       " 'able',\n",
       " 'basic',\n",
       " 'arithmetic',\n",
       " '4-digit',\n",
       " 'numbers',\n",
       " 'age',\n",
       " 'two',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "767359b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not = Arkadaşlar python da List comprehension denilen bir kavram var. Hocanın 4.18 de yaptığı döngüyü şu şekilde tek satırda yazabiliriz:\n",
    "\n",
    "# filtered_words = [i for i in word if not i in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cffdc4",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ab0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bir kelimenin kökünü almaya stemming diyoruz mesela driving kelimesinin kökü drive dır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c727d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d09f309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ab190cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = ['drive','driving','driver','drives','drove','cats','children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae865cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\n",
      "drive\n",
      "driver\n",
      "drive\n",
      "drove\n",
      "cat\n",
      "children\n"
     ]
    }
   ],
   "source": [
    "for i in words2:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c2155",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging ( Cümlenin Öğeleri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44bae89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aleyna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a0569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"Friedrich Wilhelm Nietzsche was a German philosopher, prose poet, cultural critic, philologist, and composer whose work has exerted a profound influence on contemporary philosophy. He began his career as a classical philologist before turning to philosophy. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e0500db",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nltk.word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa59371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Friedrich', 'NNP'),\n",
       " ('Wilhelm', 'NNP'),\n",
       " ('Nietzsche', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('German', 'JJ'),\n",
       " ('philosopher', 'NN'),\n",
       " (',', ','),\n",
       " ('prose', 'JJ'),\n",
       " ('poet', 'NN'),\n",
       " (',', ','),\n",
       " ('cultural', 'JJ'),\n",
       " ('critic', 'NN'),\n",
       " (',', ','),\n",
       " ('philologist', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('composer', 'NN'),\n",
       " ('whose', 'WP$'),\n",
       " ('work', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('exerted', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('profound', 'JJ'),\n",
       " ('influence', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('contemporary', 'JJ'),\n",
       " ('philosophy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('began', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('career', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('classical', 'JJ'),\n",
       " ('philologist', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('turning', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('philosophy', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac9021",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7639e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bir cümle içerisindeki kişi isimleri, organizasyon isimleri,yer isimleri,tarihler gibi bilgileri bulmayı amaçlıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3258c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Aleyna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "159a48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Aleyna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64b77d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"Steven Paul Jobs (February 24, 1955 – October 5, 2011) was an American entrepreneur, industrial designer, media proprietor, and investor. He was the co-founder, chairman, and CEO of Apple; the chairman and majority shareholder of Pixar; a member of The Walt Disney Company's board of directors following its acquisition of Pixar; and the founder, chairman, and CEO of NeXT. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "285a98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nltk.word_tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5ac0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b1eb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_ent = nltk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60fcd5cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svgling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree\\tree.py:783\u001b[0m, in \u001b[0;36mTree._repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_svg_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 783\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msvgling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_tree\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_tree(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_repr_svg_()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Steven', 'NNP')]), Tree('PERSON', [('Paul', 'NNP'), ('Jobs', 'NNP')]), ('(', '('), ('February', 'NNP'), ('24', 'CD'), (',', ','), ('1955', 'CD'), ('–', 'NNP'), ('October', 'NNP'), ('5', 'CD'), (',', ','), ('2011', 'CD'), (')', ')'), ('was', 'VBD'), ('an', 'DT'), Tree('GPE', [('American', 'JJ')]), ('entrepreneur', 'NN'), (',', ','), ('industrial', 'JJ'), ('designer', 'NN'), (',', ','), ('media', 'NNS'), ('proprietor', 'NN'), (',', ','), ('and', 'CC'), ('investor', 'NN'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('co-founder', 'NN'), (',', ','), ('chairman', 'NN'), (',', ','), ('and', 'CC'), Tree('ORGANIZATION', [('CEO', 'NNP')]), ('of', 'IN'), Tree('GPE', [('Apple', 'NNP')]), (';', ':'), ('the', 'DT'), ('chairman', 'NN'), ('and', 'CC'), ('majority', 'NN'), ('shareholder', 'NN'), ('of', 'IN'), Tree('GPE', [('Pixar', 'NNP')]), (';', ':'), ('a', 'DT'), ('member', 'NN'), ('of', 'IN'), ('The', 'DT'), Tree('ORGANIZATION', [('Walt', 'NNP'), ('Disney', 'NNP'), ('Company', 'NNP')]), (\"'s\", 'POS'), ('board', 'NN'), ('of', 'IN'), ('directors', 'NNS'), ('following', 'VBG'), ('its', 'PRP$'), ('acquisition', 'NN'), ('of', 'IN'), Tree('GPE', [('Pixar', 'NNP')]), (';', ':'), ('and', 'CC'), ('the', 'DT'), ('founder', 'NN'), (',', ','), ('chairman', 'NN'), (',', ','), ('and', 'CC'), Tree('ORGANIZATION', [('CEO', 'NNP')]), ('of', 'IN'), Tree('ORGANIZATION', [('NeXT', 'NNP')]), ('.', '.')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_ent.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45036eb6",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953830d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kök alma işlemidir stemming ile farkı ise stemming yaptıgımız zaman sadece kelimenin sonundaki ekleri atıyor fakat lemmatizing ile gerçekten kelimenin köklerine daha iyi inebiliyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = ['drive','driving','driver','drives','drove','cats','children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in words2:\n",
    "    print(lem.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem.lemmatize('driving','v')  # burada fiil oldugunu belirtirsek drive a cevirebilirdi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bcfae",
   "metadata": {},
   "source": [
    "### Corpus ve Corpora "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41367e2",
   "metadata": {},
   "source": [
    "#### Corpus(külliyat) = Doğal dil işleme içerisinde kullandığımız metin  Corpora: Corpus'un çoğulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus örnekleri : bir yazarın kitapları, Wikipedia, bir sitedeki yazılar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc46fa6-bce5-416b-a932-9e53055a2511",
   "metadata": {},
   "source": [
    "### Corpus bulma :\n",
    "#####  KAGGLE(verileri bulmak için iyi bir platform),GUTENBER(binlerce kitap bulunuyor),WİKİPEDİA (kelimeler bulmak için),COMMON CRAWL(web sitesi arşivleme projesidir , milyarlarca sitedeki yazılara ulaşabiliriz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333f5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
